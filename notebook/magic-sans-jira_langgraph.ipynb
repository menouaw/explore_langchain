{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-26T15:48:47.535973800Z",
     "start_time": "2026-01-26T15:48:41.891831600Z"
    }
   },
   "source": [
    "import os\n",
    "import glob\n",
    "from typing import Literal\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from langchain_openai import AzureChatOpenAI, AzureOpenAIEmbeddings\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.tools import tool\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "from langgraph.graph import StateGraph, MessagesState, START, END\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "RESOURCES_DIR = \"resources\"\n",
    "VECTORSTORE_PATH = \"../vectorstore_faiss\"\n",
    "CHUNK_SIZE = 1000\n",
    "CHUNK_OVERLAP = 200"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-26T15:48:49.424977200Z",
     "start_time": "2026-01-26T15:48:49.304007200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def init_models():\n",
    "    \"\"\"initialisation des deux modèles (conversation+plongement)\"\"\"\n",
    "    model = AzureChatOpenAI(\n",
    "        # TODO: variabliser dans le .env\n",
    "        azure_endpoint=os.environ.get(\"AZURE_OPENAI_CHAT_ENDPOINT\",\n",
    "                                      \"https://menoua.openai.azure.com/openai/deployments/gpt-4.1/chat/completions?api-version=2025-01-01-preview\"),\n",
    "        azure_deployment=os.environ.get(\"AZURE_OPENAI_CHAT_DEPLOYMENT\", \"gpt-41\"),\n",
    "        api_version=os.environ.get(\"AZURE_OPENAI_CHAT_API_VERSION\", \"2025-01-01-preview\"),\n",
    "        temperature=0,\n",
    "    )\n",
    "\n",
    "    embeddings = AzureOpenAIEmbeddings(\n",
    "        azure_endpoint=os.environ[\"AZURE_OPENAI_ENDPOINT\"],\n",
    "        azure_deployment=os.environ[\"AZURE_OPENAI_DEPLOYMENT_NAME\"],\n",
    "        openai_api_version=os.environ[\"AZURE_OPENAI_API_VERSION\"],\n",
    "        chunk_size=64,\n",
    "    )\n",
    "\n",
    "    return model, embeddings"
   ],
   "id": "e275364de5ba061c",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-26T13:44:41.959691900Z",
     "start_time": "2026-01-26T13:44:41.934411800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_pdf_documents(resources_dir: str) -> list:\n",
    "    pdf_files = glob.glob(os.path.join(resources_dir, \"*.pdf\"))\n",
    "\n",
    "    all_docs = []\n",
    "    for pdf_path in pdf_files:\n",
    "        print(f\"Chargement de: {pdf_path}\")\n",
    "        loader = PyPDFLoader(pdf_path)\n",
    "        docs = loader.load()\n",
    "        all_docs.extend(docs)\n",
    "        print(f\"  -> {len(docs)} pages chargées\")\n",
    "\n",
    "    print(f\"\\nTotal: {len(all_docs)} pages chargées depuis {len(pdf_files)} fichiers\")\n",
    "    return all_docs\n",
    "\n",
    "\n",
    "def split_documents(docs: list, chunk_size: int = CHUNK_SIZE, chunk_overlap: int = CHUNK_OVERLAP) -> list:\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        add_start_index=True,\n",
    "    )\n",
    "    splits = text_splitter.split_documents(docs)\n",
    "    print(f\"Documents découpés en {len(splits)} morceaux\")\n",
    "    return splits\n",
    "\n",
    "\n",
    "def create_or_load_vectorstore(embeddings, resources_dir: str = RESOURCES_DIR,\n",
    "                               vectorstore_path: str = VECTORSTORE_PATH,\n",
    "                               force_rebuild: bool = False) -> FAISS:\n",
    "\n",
    "    # vérifie si la bdd existe déjà\n",
    "    if os.path.exists(vectorstore_path) and not force_rebuild:\n",
    "        print(f\"Chargement de la BDD existante depuis {vectorstore_path}...\")\n",
    "        vectorstore = FAISS.load_local(\n",
    "            vectorstore_path,\n",
    "            embeddings,\n",
    "            allow_dangerous_deserialization=True\n",
    "        )\n",
    "        print(f\"BDD chargée avec succès\")\n",
    "        return vectorstore\n",
    "\n",
    "    print(\"Création d'une nouvelle BDD...\")\n",
    "\n",
    "    docs = load_pdf_documents(resources_dir)\n",
    "    splits = split_documents(docs)\n",
    "\n",
    "    print(\"Création des plongements et de la BDD FAISS...\")\n",
    "    vectorstore = FAISS.from_documents(documents=splits, embedding=embeddings)\n",
    "\n",
    "    vectorstore.save_local(vectorstore_path)\n",
    "    print(f\"BDD sauvegardée dans {vectorstore_path}\")\n",
    "\n",
    "    return vectorstore\n"
   ],
   "id": "a08917ee35b34b3",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "_model = None\n",
    "_retriever = None\n",
    "\n",
    "\n",
    "def create_retriever_tool(vectorstore):\n",
    "    global _retriever\n",
    "    _retriever = vectorstore.as_retriever(search_kwargs={\"k\": 4})\n",
    "\n",
    "    @tool\n",
    "    def retrieve_documents(query: str) -> str:\n",
    "        \"\"\"recherche et retourne des informations pertinentes depuis les documents PDF.\"\"\"\n",
    "        docs = _retriever.invoke(query)\n",
    "        return \"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "\n",
    "    return retrieve_documents\n"
   ],
   "id": "49443bbbb6d9ebbd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "GRADE_PROMPT = (\n",
    "    \"You are a grader assessing relevance of a retrieved document to a user question.\\n\"\n",
    "    \"Here is the retrieved document:\\n\\n{context}\\n\\n\"\n",
    "    \"Here is the user question: {question}\\n\"\n",
    "    \"If the document contains keyword(s) or semantic meaning related to the user question, grade it as relevant.\\n\"\n",
    "    \"Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\"\n",
    ")\n",
    "\n",
    "REWRITE_PROMPT = (\n",
    "    \"Look at the input and try to reason about the underlying semantic intent / meaning.\\n\"\n",
    "    \"Here is the initial question:\\n\"\n",
    "    \"-------\\n\"\n",
    "    \"{question}\\n\"\n",
    "    \"-------\\n\"\n",
    "    \"Formulate an improved question:\"\n",
    ")\n",
    "\n",
    "GENERATE_PROMPT = (\n",
    "    \"You are an assistant for question-answering tasks.\\n\"\n",
    "    \"Use the following pieces of retrieved context to answer the question.\\n\"\n",
    "    \"If you don't know the answer, just say that you don't know.\\n\"\n",
    "    \"Use three sentences maximum and keep the answer concise.\\n\"\n",
    "    \"Question: {question}\\n\"\n",
    "    \"Context: {context}\"\n",
    ")"
   ],
   "id": "a8cb9ca25d827305",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class GradeDocuments(BaseModel):\n",
    "    \"\"\"évalue la pertinence des documents\"\"\"\n",
    "    binary_score: str = Field(\n",
    "        description=\"Relevance score: 'yes' if relevant, or 'no' if not relevant\"\n",
    "    )\n",
    "\n",
    "\n",
    "def generate_query_or_respond(state: MessagesState):\n",
    "    \"\"\"génère une requête de recherche ou répond directement\"\"\"\n",
    "    global _model, _retriever_tool\n",
    "    response = _model.bind_tools([_retriever_tool]).invoke(state[\"messages\"])\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "def grade_documents(state: MessagesState) -> Literal[\"generate_answer\", \"rewrite_question\"]:\n",
    "    \"\"\"évalue la pertinence des documents récupérés\"\"\"\n",
    "    global _model\n",
    "    question = state[\"messages\"][0].content\n",
    "    context = state[\"messages\"][-1].content\n",
    "\n",
    "    prompt = GRADE_PROMPT.format(question=question, context=context)\n",
    "    response = _model.with_structured_output(GradeDocuments).invoke(\n",
    "        [{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "\n",
    "    if response.binary_score == \"yes\":\n",
    "        return \"generate_answer\"\n",
    "    else:\n",
    "        return \"rewrite_question\"\n",
    "\n",
    "\n",
    "def rewrite_question(state: MessagesState):\n",
    "    \"\"\"reformule la question pour améliorer la recherche\"\"\"\n",
    "    global _model\n",
    "    question = state[\"messages\"][0].content\n",
    "    prompt = REWRITE_PROMPT.format(question=question)\n",
    "    response = _model.invoke([{\"role\": \"user\", \"content\": prompt}])\n",
    "    return {\"messages\": [HumanMessage(content=response.content)]}\n",
    "\n",
    "\n",
    "def generate_answer(state: MessagesState):\n",
    "    \"\"\"génère une réponse basée sur le contexte récupéré\"\"\"\n",
    "    global _model\n",
    "    question = state[\"messages\"][0].content\n",
    "    context = state[\"messages\"][-1].content\n",
    "    prompt = GENERATE_PROMPT.format(question=question, context=context)\n",
    "    response = _model.invoke([{\"role\": \"user\", \"content\": prompt}])\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "def build_rag_agent(model, retriever_tool):\n",
    "    \"\"\"construit le graphe de l'agent RAG avec LangGraph\"\"\"\n",
    "    global _model, _retriever_tool\n",
    "    _model = model\n",
    "    _retriever_tool = retriever_tool\n",
    "\n",
    "    workflow = StateGraph(MessagesState)\n",
    "\n",
    "    workflow.add_node(generate_query_or_respond)\n",
    "    workflow.add_node(\"retrieve\", ToolNode([retriever_tool]))\n",
    "    workflow.add_node(rewrite_question)\n",
    "    workflow.add_node(generate_answer)\n",
    "\n",
    "    workflow.add_edge(START, \"generate_query_or_respond\")\n",
    "\n",
    "    workflow.add_conditional_edges(\n",
    "        \"generate_query_or_respond\",\n",
    "        tools_condition,\n",
    "        {\n",
    "            \"tools\": \"retrieve\",\n",
    "            END: END,\n",
    "        },\n",
    "    )\n",
    "\n",
    "    workflow.add_conditional_edges(\n",
    "        \"retrieve\",\n",
    "        grade_documents,\n",
    "    )\n",
    "\n",
    "    workflow.add_edge(\"generate_answer\", END)\n",
    "    workflow.add_edge(\"rewrite_question\", \"generate_query_or_respond\")\n",
    "\n",
    "    graph = workflow.compile()\n",
    "    return graph\n"
   ],
   "id": "e5d93f2cd229637a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def chat_with_agent(agent, question: str, verbose: bool = True):\n",
    "    if verbose:\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Question: {question}\")\n",
    "        print('='*60)\n",
    "\n",
    "    response_content = \"\"\n",
    "    for chunk in agent.stream({\"messages\": [{\"role\": \"user\", \"content\": question}]}):\n",
    "        for node, update in chunk.items():\n",
    "            if verbose:\n",
    "                print(f\"\\n[Noeud: {node}]\")\n",
    "                update[\"messages\"][-1].pretty_print()\n",
    "\n",
    "            if node == \"generate_answer\" or (node == \"generate_query_or_respond\" and not update[\"messages\"][-1].tool_calls):\n",
    "                response_content = update[\"messages\"][-1].content\n",
    "\n",
    "    return response_content\n",
    "\n",
    "\n",
    "def interactive_mode(agent):\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Agent RAG - Mode interactif\")\n",
    "    print(\"Tapez 'quit' ou 'exit' pour quitter\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            question = input(\"\\nVotre question: \").strip()\n",
    "\n",
    "            if question.lower() in ['quit', 'exit', 'q']:\n",
    "                print(\"Au revoir!\")\n",
    "                break\n",
    "\n",
    "            if not question:\n",
    "                continue\n",
    "\n",
    "            chat_with_agent(agent, question)\n",
    "\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\nInterruption. Au revoir!\")\n",
    "            break"
   ],
   "id": "c2d2eff578b3f072",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"=\"*60)\n",
    "print(\"Initialisation de l'agent\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\n1. Initialisation des modèles Azure OpenAI...\")\n",
    "model, embeddings = init_models()\n",
    "print(\"Modèles initialisés\")\n",
    "\n",
    "print(\"\\n2. Préparation de la BDD...\")\n",
    "vectorstore = create_or_load_vectorstore(\n",
    "    embeddings,\n",
    "    resources_dir=RESOURCES_DIR,\n",
    "    force_rebuild=False\n",
    ")\n",
    "\n",
    "print(\"\\n3. Création de l'outil de recherche...\")\n",
    "retriever_tool = create_retriever_tool(vectorstore)\n",
    "print(\"Outil de recherche créé\")\n",
    "\n",
    "print(\"\\n4. Construction de l'agent...\")\n",
    "agent = build_rag_agent(model, retriever_tool)\n",
    "print(\"Agent prêt\")"
   ],
   "id": "e67fd03df61dc8a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "interactive_mode(agent)",
   "id": "8c33602986e77567",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
